version: '3.8'


services:
 kafka-1:
   image: bitnami/kafka:3.7
   container_name: kafka-1
   hostname: kafka-1
   ports:
     - "9092:9092"
     - "9093:9093"
   networks:
     - confluent
   environment:
     KAFKA_ENABLE_KRAFT: "yes"
     KAFKA_CFG_NODE_ID: "1"
     KAFKA_KRAFT_CLUSTER_ID: "kraft-cluster"
     KAFKA_CFG_PROCESS_ROLES: "broker,controller"
     KAFKA_CFG_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
     KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:9095"
     KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,EXTERNAL://:9093,CONTROLLER://:9095
     KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:9092,EXTERNAL://localhost:9093
     KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
     KAFKA_CFG_INTER_BROKER_LISTENER_NAME: PLAINTEXT
     KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: "true"
     KAFKA_CFG_DELETE_TOPIC_ENABLE: "true"
     KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
   volumes:
     - kafka_data:/bitnami/kafka


 hadoop-namenode:
   image: apache/hadoop:3.4.1
   container_name: hadoop-namenode
   hostname: hadoop-namenode
   user: "root"
   restart: always
   platform: linux/amd64
   deploy:
     resources:
       limits:
         cpus: "1.0"
         memory: "2g"
   shm_size: 10G
   ports:
     - "9870:9870"
     - "9000:9000"
   volumes:
     - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
     - ./config/hdfs-site-namenode.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
     - ./namenode_entrypoint.sh:/namenode_entrypoint.sh
   entrypoint: ["/bin/bash", "/namenode_entrypoint.sh"]
   command: ["hdfs", "namenode"]


 hadoop-datanode-1:
   image: apache/hadoop:3.4.1
   container_name: hadoop-datanode-1
   hostname: hadoop-datanode-1
   user: "root"
   restart: always
   platform: linux/amd64
   deploy:
     resources:
       limits:
         cpus: "1.0"
         memory: "2g"
   shm_size: 10G
   depends_on:
     - hadoop-namenode
   ports:
     - "9864:9864"
     - "9970:9970"
   volumes:
     - ./config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
     - ./config/hdfs-site-datanode-1.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
     - ./datanode_entrypoint.sh:/datanode_entrypoint.sh
   entrypoint: ["/bin/bash", "/datanode_entrypoint.sh"]
   command: ["hdfs", "datanode"]


 spark-master:
    image: apache/spark:3.5.4
    container_name: spark-master
    hostname: spark-master
    networks:
      - confluent
    ports:
      - "8080:8080"   # Spark master web UI
      - "7077:7077"   # Spark master service
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master", "--host", "spark-master"]
    environment:
      - SPARK_NO_DAEMONIZE=true
    restart: always

 spark-worker-1:
    image: apache/spark:3.5.4
    container_name: spark-worker-1
    hostname: spark-worker-1
    networks:
      - confluent
    depends_on:
      - spark-master
    environment:
      - SPARK_NO_DAEMONIZE=true
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]
    restart: always

 spark-worker-2:
    image: apache/spark:3.5.4
    container_name: spark-worker-2
    hostname: spark-worker-2
    networks:
      - confluent
    depends_on:
      - spark-master
    environment:
      - SPARK_NO_DAEMONIZE=true
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077"]
    restart: always


volumes:
 kafka_data:


networks:
 confluent:
